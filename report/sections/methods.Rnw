\section{Methods}

\begin{document}
$ \textit{Logistic regression} $ is one of the most commonly used tools for applied statistics
and discrete data analysis. In this model, we have a binary output variable Y, and we want to model the conditional probability  
\begin{equation}
Pr\left(Y=1\,\middle|\,X = x\right)
\end{equation}
as a function of $ \textit{x} $; any unknown parameters in the function are to be estimated by maximum likelihood.\par
Formally, the model logistic regression model is that
\begin{equation}
log \frac{p(x)}{1-p(x)} = \beta_0 + x \cdot \beta
\end{equation}

Solving for p(x), this gives 
\begin{equation}
p(x) = \frac{e^{\beta_0+x\cdot\beta}}{1 + e^{\beta_0+x\cdot\beta}}
\end{equation}

To minimize the mis-classification rate, we should predict Y = 1 when p â‰¥ 0.5
and Y = 0 when p < 0.5. This means guessing 1 whenever $ \beta_0+x\cdot\beta $ is non-negative,
and 0 otherwise. Therefore, the decision boundary separating the two predicted classes is the solution of $ \beta_0+x\cdot\beta = 0 $,
\end{document}
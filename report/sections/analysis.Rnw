\section{Analysis}
\subsection{Logistic Regression}

$ \textit{Logistic regression} $ is one of the most commonly used tools for applied statistics
and discrete data analysis. In this model, we have a binary output variable Y, and we want to model the conditional probability  
\begin{equation}
Pr\left(Y=1\,\middle|\,X = x\right)
\end{equation}
as a function of $ \textit{x} $; any unknown parameters in the function are to be estimated by maximum likelihood.\par
Formally, the model logistic regression model is that
\begin{equation}
log \frac{p(x)}{1-p(x)} = \beta_0 + x \cdot \beta
\end{equation}

Solving for p(x), this gives 
\begin{equation}
p(x) = \frac{e^{\beta_0+x\cdot\beta}}{1 + e^{\beta_0+x\cdot\beta}}
\end{equation}

To minimize the mis-classification rate, we should predict Y = 1 when p > 0.5
and Y = 0 when p < 0.5. This means guessing 1 whenever $ \beta_0+x\cdot\beta $ is non-negative,
and 0 otherwise. Therefore, the decision boundary separating the two predicted classes is the solution of $ \beta_0+x\cdot\beta = 0 $.

Since Logistic Regression is a classification method, we'll have to transform our labels, $\textit{CDR3}$, into binary labels at the threshold of 0.15. Now we are ready to perform cross validation on the data set to gain some insight on the accuracy of logistic regression on this particular problem. I calculated three statistics for each iteration of cross validation. Precision is the percentage of the positive predictions were correct. Recall is the percentage of positive cases that were correctly classified. Lastly, F1-score considers both precision and recall. The 5-fold cross validation results are displayed in the below table, and on average of the 5-fold, the F1-score is around 76 percent, which is not bad.

<<results=tex>>==
load("../data/logistic-result.csv")
xtable(stats.df, caption = "Logistic Regression Statistics of 5-Fold Cross Validation")
@
